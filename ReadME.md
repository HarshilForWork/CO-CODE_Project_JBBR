
# PDF MCQ Generator using Streamlit and Ollama

This project is a **PDF-based MCQ Generator** built with **Streamlit** and  **LangChain** , utilizing **Qwen2** for reading PDFs and **DeepSeek** for generating multiple-choice questions (MCQs).

## Features üöÄ

* **Upload a PDF** and extract text automatically.
* **Generate MCQs dynamically** using AI-powered models.
* **Track quiz performance** with real-time metrics.
* **Receive AI-based feedback** for improvement.

## Tech Stack üõ†Ô∏è

* **Streamlit** - Web interface
* **LangChain** - Text processing and retrieval
* **Ollama** - Local AI models (Qwen2 & DeepSeek)
* **PDFPlumber** - PDF text extraction
* **spaCy & NLTK** - NLP-based distractor generation
* **DistilBERT** - Extract answers from context
* **FAISS** - Vector-based retrieval

## Installation üîß

### **1. Clone the Repository**

```bash
git clone https://github.com/your-repo/pdf-mcq-generator.git
cd pdf-mcq-generator
```

### **2. Install Dependencies**

```bash
pip install -r requirements.txt
```

### **3. Download NLP Models**

```bash
python -m spacy download en_core_web_sm

import nltk
nltk.download('wordnet')
nltk.download('punkt')
```

### **4. Run the Application**

```bash
streamlit run app.py
```

---

## **Workflow of the PDF-based MCQ Generation System**

This system processes a PDF, extracts key information, generates multiple-choice questions (MCQs), and presents an interactive quiz interface.

### **1. User Uploads PDF (`app.py`)**

* The user uploads a PDF via Streamlit‚Äôs file uploader.
* The file content is passed to `DocumentProcessor` for processing.

### **2. Document Processing (`document_processor.py`)**

* **Extract Text from PDF** ‚Üí Uses `PDFPlumberLoader`.
* **Split Text into Chunks** ‚Üí Uses `RecursiveCharacterTextSplitter`.
* **Initialize AI Models** ‚Üí Uses `OllamaLLM` and `InMemoryVectorStore`.
* **Return Processed Chunks** to `app.py` for MCQ generation.

### **3. Generate MCQs (`mcq_generator.py`)**

* **Select a Text Chunk** ‚Üí Choose a portion of text.
* **Generate Question using LLM** ‚Üí Prompt `OllamaLLM` to create a question.
* **Extract Answer using BERT QA Pipeline** ‚Üí Identify correct answers.
* **Generate Distractors** ‚Üí Find incorrect answer choices.
* **Assess Difficulty Level** ‚Üí Determine question complexity.
* **Return MCQ** ‚Üí Send question and options back to the frontend.

### **4. Interactive Quiz (`app.py`)**

* **Display MCQ to User** ‚Üí Show questions and answer choices.
* **User Submits Answer** ‚Üí Validate the response.
* **Track Performance** ‚Üí Store correct/incorrect attempts.
* **Move to Next Question** ‚Üí Continue the quiz.
* **Quiz Completion** ‚Üí Generate a final report.

### **5. AI-Based Performance Analysis (`app.py`)**

* **Calculate Quiz Metrics** ‚Üí Score, accuracy, response time.
* **Generate AI-Based Feedback** ‚Üí Insights and improvement tips.
* **Display Results to User** ‚Üí Show a structured performance summary.

---

## **Component Responsibilities**

| **Component**                  | **Responsibilities**                             |
| ------------------------------------ | ------------------------------------------------------ |
| **Frontend (`app.py`)**      | Displays MCQs, collects responses, and shows results.  |
| **Document Processor**         | Extracts and splits text from PDFs.                    |
| **MCQ Generator**              | Generates MCQs with distractors and difficulty levels. |
| **AI Models (`OllamaLLM`)**  | Creates questions and provides AI-based feedback.      |
| **BERT QA Model**              | Extracts correct answers from the text.                |
| **NLP Components (`spaCy`)** | Generates synonyms and distractors.                    |

This system ensures **dynamic question generation, interactive learning, and AI-driven feedback** for an engaging quiz experience. üöÄ
